# ПІДХОДИ ДО ПІДВИЩЕННЯ ЯКОСТІ СЕМАНТИЧНОГО ПОШУКУ В БАЗАХ ЗНАНЬ ІЗ ВИКОРИСТАННЯМ ВЕКТОРНИХ ПОДАНЬ ТА БЕНЧМАРК-ОЦІНЮВАННЯ

У цій роботі акцент зроблено на експериментальній реалізації та візуалізації результатів семантичного пошуку в задачах доступу до корпоративних знань. Запропоновано застосунок, що поєднує підготовку документів, їх чанкінг, побудову індексів для кількох типів ембедингів і подальше оцінювання якості пошуку за набором еталонних запитів. Основний фокус подано на аналізі фактичної пошукової видачі, а порівняння моделей використано як інструмент пояснення отриманих результатів. Дослідження орієнтоване на відтворюваність експериментів, порівнюваність результатів і наочну інтерпретацію через веб-інтерфейс. Окрему увагу приділено узгодженню офлайн-метрик (nDCG, MRR, Recall, Precision) із фактичною релевантністю видачі для користувача.

Ключові слова: семантичний пошук, ембединги, векторний індекс, бенчмарк, релевантність, база знань, інформаційний пошук.

Швидкий доступ до релевантних знань є критично важливим для сучасних інформаційних систем, де обсяг неструктурованих документів постійно зростає. За таких умов традиційний лексичний пошук часто втрачає ефективність через синонімію та варіативність формулювань, тому практичну цінність мають методи семантичного пошуку, що працюють зі змістовими векторними поданнями текстів.

Метою роботи є підвищення якості семантичного пошуку в базі знань шляхом порівняльного аналізу моделей векторних подань у межах єдиного програмного середовища. Для цього реалізовано уніфікований пайплайн підготовки даних, побудовано індекси для кількох моделей ембедингів, організовано модуль бенчмарку з еталонними запитами та забезпечено візуальний аналіз результатів через веб-інтерфейс. Такий підхід дає змогу порівнювати моделі в однакових умовах і мінімізувати вплив побічних чинників.

Програмна реалізація побудована за модульним принципом. Дані проходять етапи нормалізації та розбиття на смислові фрагменти, після чого для кожного фрагмента обчислюється векторне подання відповідно до обраної моделі. Отримані вектори індексуються з використанням структури пошуку найближчих сусідів, що забезпечує роботу з великими колекціями документів. У застосунку передбачено підтримку кількох сімейств моделей, а для кожної моделі зберігаються службові артефакти: файл індексу, матриця векторів, метадані щодо документів і параметрів побудови. Це створює основу для відтворюваного порівняння якості та швидкодії.

На сторінці пошуку можна оцінити не лише факт повернення релевантного фрагмента, а і його позицію у видачі. Саме цей аспект є ключовим для практичного використання, оскільки кінцевий користувач зазвичай переглядає лише верхні результати. Тому якісний аналіз інтерфейсу доповнює формальні метрики й дає змогу краще зрозуміти, як модель поводиться в реальному сценарії взаємодії. Додатково інтерфейс дозволяє швидко перевіряти реакцію системи на перефразовані запити без зміни експериментальних налаштувань.

[ЗАГЛУШКА ДЛЯ РИСУНКА 1]
Підпис: Результати пошуку для запиту «косинусна схожість векторів у семантичному пошуку» (модель fasttext, топ-5).

Для демонстрації практичної цінності системи доцільно окремо показувати приклади запитів із коментарем до топ-результатів. Для AI-запиту «косинусна схожість векторів у семантичному пошуку» у наведеному сценарії пошуку отримано високі значення локальної релевантності у верхніх позиціях (98.8%, 98.8%, 98.5% для перших трьох результатів), що демонструє коректне потрапляння в тематичний кластер.

[ЗАГЛУШКА ДЛЯ РИСУНКА 2]
Підпис: Результати пошуку для запиту «кінематика COREXY у системах FDM-друку» (модель SBERT, топ-5).

Другий запит обрано з іншої предметної області (адитивне виробництво), що дозволяє перевірити роботу системи поза AI-тематикою. Для запиту «кінематика COREXY у системах FDM-друку» верхні результати також є релевантними предметній області (63.0%, 57.5%, 47.9% для перших трьох позицій), що підтверджує здатність системи працювати на неоднорідному корпусі документів.

[ЗАГЛУШКА ДЛЯ РИСУНКА 3]
Підпис: Сторінка бенчмарку з відображенням метрик для кількох моделей.

Для емпіричної перевірки якості використовувався benchmark-набір (87 запитів, top_k=10), що містить перелік тестових запитів, qrels-розмітку релевантних фрагментів і єдині параметри оцінювання. У дослідженні аналізувалися nDCG@10, MRR@10, Recall@10 і P@10. За підсумками запуску найкраще ранжування за nDCG@10 показала модель paraphrase-multilingual-MiniLM-L12-v2 (0.5444), далі TF-IDF (0.4886), BERT (0.3237), fastText (0.1046) та word2vec (0.0766). За Recall@10 найвищий результат у TF-IDF (0.7883), тоді як SBERT має 0.7375, BERT — 0.4655, fastText — 0.1801, word2vec — 0.1121. За MRR@10 SBERT також лідирує (0.5366), а TF-IDF демонструє 0.4640. Такий розподіл показує, що контекстна модель забезпечує кращу якість ранніх позицій у видачі, тоді як TF-IDF лишається сильним базовим підходом за повнотою.

[ЗАГЛУШКА ДЛЯ РИСУНКА 4]
Підпис: Приклад сторінки документів/чанків для валідації джерел і релевантності.

Окремим практичним аспектом є підготовка демонстраційних матеріалів для тез. Оскільки між різними запусками можливі незначні відхилення (оновлення даних, параметрів, версій бібліотек), доцільно використовувати фіксований демо-сценарій із попередньо збереженими результатами бенчмарку. У такому разі варто фіксувати версію набору даних і параметри запуску, використовувати узгоджений набір скріншотів із однієї сесії та робити акцент на відносному порівнянні моделей, а не на одиничних абсолютних значеннях. Це спрощує перевірку висновків і робить інтерпретацію результатів прозорою для рецензента.

Отже, у роботі запропоновано практичний підхід до підвищення якості семантичного пошуку в базах знань шляхом інтеграції підготовки даних, векторної індексації, бенчмарк-оцінювання та веб-візуалізації результатів. Запропонований контур дозволяє системно порівнювати моделі ембедингів у відтворюваному середовищі й оперативно оцінювати наслідки змін у пайплайні. Отримані результати узгоджуються з висновками попередніх тез і можуть бути використані як основа для подальшого розвитку систем семантичного та гібридного пошуку, а також для задач контролю якості в RAG-сценаріях.

Список використаних джерел
1. Нестеренко В. В., Русакова Н. Є. Порівняльний аналіз ефективності моделей векторних ембеддінгів для задач семантичного пошуку в корпоративних базах знань // Innovative Research in Science and Economy : матеріали ІІ Міжнар. наук.-практ. конф. С. 127.
2. Manning C. D., Raghavan P., Schütze H. Introduction to Information Retrieval. Cambridge : Cambridge University Press, 2008. 482 p.
3. Reimers N., Gurevych I. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks // Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP-IJCNLP). 2019. P. 3982–3992.
4. Johnson J., Douze M., Jégou H. Billion-scale similarity search with GPUs // IEEE Transactions on Big Data. 2019. Vol. 7, No. 3. P. 535–547.
