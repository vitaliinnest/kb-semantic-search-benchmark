# ПІДХОДИ ДО ПІДВИЩЕННЯ ЯКОСТІ СЕМАНТИЧНОГО ПОШУКУ В БАЗАХ ЗНАНЬ ІЗ ВИКОРИСТАННЯМ ВЕКТОРНИХ ПОДАНЬ ТА БЕНЧМАРК-ОЦІНЮВАННЯ

У роботі розглянуто практичний підхід до побудови та порівняння моделей семантичного пошуку в задачах доступу до корпоративних знань. Запропоновано прикладний застосунок, що поєднує підготовку документів, їх чанкінг, побудову індексів для кількох типів ембедингів і подальше оцінювання якості пошуку за набором еталонних запитів. Дослідження орієнтоване на відтворюваність експериментів, порівнюваність результатів і наочну інтерпретацію через веб-інтерфейс. Окрему увагу приділено узгодженню офлайн-метрик (nDCG, MRR, Recall, Precision) із практичною релевантністю видачі для користувача. Показано, що використання єдиного контуру «індексація – пошук – бенчмарк – візуалізація» дає змогу не лише порівнювати моделі, а й системно покращувати якість інформаційного пошуку в прикладних сценаріях.

Ключові слова: семантичний пошук, ембединги, векторний індекс, бенчмарк, релевантність, база знань, інформаційний пошук.

Швидкий доступ до релевантних знань є критично важливим для сучасних інформаційних систем. У прикладних умовах, де обсяг неструктурованих документів постійно зростає, традиційний лексичний пошук часто втрачає ефективність через синонімію, варіативність формулювань та доменно-специфічну термінологію. У зв’язку з цим усе більшої актуальності набувають методи семантичного пошуку, які оперують не словами, а змістовими векторними поданнями текстів. У попередніх тезах автора було закладено методичну основу порівняння підходів до векторизації текстів і сформульовано критерії оцінювання якості пошуку, а в поточній роботі цю лінію продовжено за рахунок практичної реалізації повного експериментального контуру в єдиному застосунку.

Метою роботи є підвищення якості семантичного пошуку в базі знань шляхом порівняльного аналізу моделей векторних подань у межах єдиного програмного середовища. Для досягнення мети реалізовано уніфікований пайплайн підготовки даних, побудовано індекси для кількох типів моделей ембедингів, організовано модуль бенчмарку з еталонними запитами та релевантними відповідями, а також забезпечено візуальний аналіз результатів через веб-інтерфейс. Така постановка дослідження дозволяє порівнювати моделі в однакових умовах, мінімізуючи вплив побічних чинників на підсумкову оцінку.

Програмна реалізація побудована за модульним принципом. Дані проходять етапи нормалізації та розбиття на смислові фрагменти, після чого для кожного фрагмента обчислюється векторне подання відповідно до обраної моделі. Отримані вектори індексуються з використанням структури пошуку найближчих сусідів, що забезпечує роботу з великими колекціями документів. У застосунку передбачено підтримку кількох сімейств моделей, а для кожної моделі зберігаються службові артефакти: файл індексу, матриця векторів, метадані щодо документів і параметрів побудови. Це створює основу для відтворюваного порівняння якості та швидкодії.

[ЗАГЛУШКА ДЛЯ РИСУНКА 1]
Підпис: Інтерфейс сторінки пошуку та приклад видачі результатів.

На сторінці пошуку можна оцінити не лише факт повернення релевантного фрагмента, а і його позицію у видачі. Саме цей аспект є ключовим для практичного використання, оскільки кінцевий користувач зазвичай переглядає лише верхні результати. Тому якісний аналіз інтерфейсу доповнює формальні метрики й дає змогу краще зрозуміти, як модель поводиться в реальному сценарії взаємодії.

[ЗАГЛУШКА ДЛЯ РИСУНКА 2]
Підпис: Сторінка бенчмарку з відображенням метрик для кількох моделей.

Для емпіричної перевірки якості використовувався benchmark-набір, що містить перелік тестових запитів, qrels-розмітку релевантних фрагментів і єдині параметри top-k видачі. У дослідженні аналізувалися nDCG@k, MRR@k, Recall@k і Precision@k. Таке поєднання показників дає змогу оцінити як якість ранжування, так і здатність моделі знаходити релевантні відповіді загалом. Інтерпретація результатів виконувалася у двох вимірах: кількісному (за значеннями метрик) та якісному (через перегляд конкретних прикладів відповіді на запити).

[ЗАГЛУШКА ДЛЯ РИСУНКА 3]
Підпис: Порівняння моделей за nDCG@k та MRR@k.

Порівняльний аналіз показав, що контекстно-орієнтовані моделі в середньому забезпечують стабільніше ранжування для семантично складних запитів, тоді як легші моделі залишаються доцільними для сценаріїв із жорсткими обмеженнями за ресурсами. Водночас близькі значення агрегованих метрик не завжди означають однакову практичну корисність, тому додатковий перегляд джерел і чанків є необхідним етапом валідації висновків.

[ЗАГЛУШКА ДЛЯ РИСУНКА 4]
Підпис: Приклад сторінки документів/чанків для валідації джерел і релевантності.

Окремим практичним аспектом є підготовка демонстраційних матеріалів для тез. Оскільки між різними запусками можливі незначні відхилення (оновлення даних, параметрів, версій бібліотек), доцільно використовувати фіксований демо-сценарій із попередньо збереженими результатами бенчмарку. У такому разі варто фіксувати версію набору даних і параметри запуску, використовувати узгоджений набір скріншотів із однієї сесії та робити акцент на відносному порівнянні моделей, а не на одиничних абсолютних значеннях.

Отже, у роботі запропоновано практичний підхід до підвищення якості семантичного пошуку в базах знань шляхом інтеграції підготовки даних, векторної індексації, бенчмарк-оцінювання та веб-візуалізації результатів. Запропонований контур дозволяє системно порівнювати моделі ембедингів у відтворюваному середовищі й оперативно оцінювати наслідки змін у пайплайні. Отримані результати узгоджуються з висновками попередніх тез і можуть бути використані як основа для подальшого розвитку систем семантичного та гібридного пошуку, а також для задач контролю якості в RAG-сценаріях.

Список використаних джерел
1. Нестеренко О. В. Попередні тези за тематикою семантичного пошуку (у фінальній версії вказати повну бібліографію прикріплених тез).
2. Manning C. D., Raghavan P., Schütze H. Introduction to Information Retrieval. Cambridge University Press, 2008.
3. Reimers N., Gurevych I. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. EMNLP-IJCNLP, 2019.
4. Johnson J., Douze M., Jégou H. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data, 2019.
