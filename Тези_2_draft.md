# ПІДВИЩЕННЯ ЯКОСТІ СЕМАНТИЧНОГО ПОШУКУ В БАЗАХ ЗНАНЬ ІЗ ВИКОРИСТАННЯМ ВЕКТОРНИХ ПОДАНЬ

This paper presents an applied evaluation of semantic search quality in a knowledge-base retrieval system. The study uses a reproducible pipeline that combines preprocessing, chunking, vector indexing, querying, and benchmark-based assessment across two domains. Evaluation is conducted on a benchmark of 87 queries with top_k=10 using nDCG@10, MRR@10, Recall@10, and Precision@10. The findings indicate that contextual embeddings provide better relevance at top-ranked positions, while lexical methods remain a strong baseline for coverage. The proposed approach supports iterative quality control and further development of semantic and hybrid retrieval systems.

У роботі подано прикладну реалізацію семантичного пошуку для корпоративної бази знань із фокусом на фактичній пошуковій видачі. Застосунок об’єднує підготовку даних, чанкінг, побудову векторних індексів і бенчмарк-оцінювання в одному відтворюваному контурі. Порівняння моделей використано як інструмент пояснення якості результатів у веб-інтерфейсі. Практична цінність підходу полягає у можливості швидко перевіряти вплив змін моделі або параметрів індексації на кінцеву якість видачі.

Для сучасних інформаційних систем швидкий доступ до релевантних знань є критичним, а лексичний пошук часто втрачає ефективність через синонімію та варіативність формулювань [2]. Мета роботи — підвищити якість семантичного пошуку шляхом порівняння моделей векторних подань у єдиному середовищі з однаковими умовами оцінювання.

Дані нормалізуються, розбиваються на смислові фрагменти (чанки), далі векторизуються та індексуються у структурі найближчих сусідів [4]. Пошук виконується по чанках, що покращує потрапляння в локально релевантний контекст. Для кожної моделі зберігаються індекс, вектори та метадані.

Інтерфейс дозволяє оцінювати не лише наявність релевантного фрагмента, а й його позицію у топ-видачі, що критично для практичного використання. Це дає змогу поєднати кількісні метрики з якісним аналізом конкретних відповідей для реальних запитів користувача.

[ЗАГЛУШКА ДЛЯ РИСУНКА 1]
Підпис: Результати пошуку для запиту «косинусна схожість векторів у семантичному пошуку» (модель fasttext, топ-5).

Для AI-запиту «косинусна схожість векторів у семантичному пошуку» (рис. 1) у верхніх позиціях отримано 98.8%, 98.8% і 98.5% локальної релевантності, що підтверджує коректне тематичне потрапляння. Додатково виконано запит з іншої предметної області («кінематика COREXY у системах FDM-друку»), який також дав релевантну топ-видачу: 63.0%, 57.5%, 47.9% для перших трьох позицій.

[ЗАГЛУШКА ДЛЯ РИСУНКА 2]
Підпис: Сторінка бенчмарку з відображенням метрик для кількох моделей.

Якість оцінено на benchmark-наборі (87 запитів, top_k=10) за метриками nDCG@10, MRR@10, Recall@10 і P@10 (див. рис. 2). Найкращий nDCG@10 має paraphrase-multilingual-MiniLM-L12-v2 (0.5444), далі TF-IDF (0.4886) і BERT (0.3237); fastText і word2vec мають 0.1046 та 0.0766. За Recall@10 лідирує TF-IDF (0.7883), за MRR@10 — SBERT (0.5366), TF-IDF має 0.4640 [3]. Отже, контекстна модель краще ранжує верхні позиції, а TF-IDF забезпечує високу повноту. Така комбінація результатів є корисною для вибору моделі залежно від практичного пріоритету: точність перших відповідей або повнота покриття.

Запропонований підхід забезпечує відтворюване порівняння моделей і практичний контроль якості пошуку в єдиному контурі «дані — індекс — запит — оцінювання». Отримані результати узгоджуються з раніше оприлюдненими дослідженнями за цією тематикою [1] та можуть бути використані для подальшого розвитку семантичного і гібридного пошуку.

Список використаних джерел
1. Нестеренко В. В., Русакова Н. Є. Порівняльний аналіз ефективності моделей векторних ембеддінгів для задач семантичного пошуку в корпоративних базах знань // Innovative Research in Science and Economy : матеріали ІІ Міжнар. наук.-практ. конф. С. 127.
2. Manning C. D., Raghavan P., Schütze H. Introduction to Information Retrieval. Cambridge : Cambridge University Press, 2008. 482 p.
3. Reimers N., Gurevych I. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks // Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP-IJCNLP). 2019. P. 3982–3992.
4. Johnson J., Douze M., Jégou H. Billion-scale similarity search with GPUs // IEEE Transactions on Big Data. 2019. Vol. 7, No. 3. P. 535–547.
